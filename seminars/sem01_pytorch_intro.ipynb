{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# О_итог = 0.7 * дз + 0.3 * проверочные\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array([[1,2,3,4]])\n",
    "torch.tensor([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3,4]])#.float()\n",
    "b = torch.tensor([[1,2,3,4]])#.float()\n",
    "\n",
    "# a @ b.t()\n",
    "\n",
    "a.double().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.float()\n",
    "b = b.float()\n",
    "torch.sin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7616, 0.9640, 0.9951, 0.9993]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 but got device cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-dd59bde3c202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cuda:0 but got device cpu"
     ]
    }
   ],
   "source": [
    "a.cuda() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! CUDA_VISIBLE_DEVICES=... python3 main.py ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 5)\n",
    "\n",
    "a.view(5, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1911, 2.6922, 2.8226])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np = np.random.rand(3, 5)\n",
    "\n",
    "# a_np.sum(axis=1)\n",
    "a.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 5)\n",
    "a.requires_grad = True\n",
    "b = torch.rand_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.sum(2 * a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]),)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import grad\n",
    "\n",
    "grad(res, a)\n",
    "\n",
    "# ТАК НИКТО НЕ ДЕЛАЕТ!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 5)\n",
    "a.requires_grad = True\n",
    "b = torch.rand_like(a)\n",
    "res = torch.sum(a ** 2 + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0386, 0.7273, 0.2383, 1.1436, 1.5613],\n",
      "        [1.0395, 0.7869, 0.1879, 1.1351, 0.2739],\n",
      "        [1.1067, 1.8565, 1.0047, 1.1059, 0.3418]])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "# Не None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)\n",
    "# Потому что requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 5)\n",
    "a.requires_grad = True\n",
    "b = torch.rand_like(a)\n",
    "b.requires_grad = True\n",
    "res = torch.sum(a ** 2 + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-7c77186effd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\1\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\1\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\1\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 5)\n",
    "a.requires_grad = True\n",
    "b = torch.rand_like(a)\n",
    "b.requires_grad = True\n",
    "res = torch.sum(a ** 2 + b, dim=1)\n",
    "\n",
    "res.backward()\n",
    "# Вызовет ошибку потому что res -- не тензор-скаляр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3664, 0.3963, 0.4440, 0.5355, 0.7443],\n",
      "        [0.0379, 1.6779, 0.0457, 1.7851, 0.2942],\n",
      "        [1.8270, 1.8058, 1.7667, 0.1703, 0.9204]])\n",
      "tensor([[1.3664, 1.3963, 1.4440, 1.5355, 1.7443],\n",
      "        [1.0379, 2.6779, 1.0457, 2.7851, 1.2942],\n",
      "        [2.8270, 2.8058, 2.7667, 1.1703, 1.9204]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 5)\n",
    "a.requires_grad = True\n",
    "b = torch.rand_like(a)\n",
    "b.requires_grad = True\n",
    "res1 = torch.sum(a ** 2 + b)\n",
    "res2 = torch.sum(a + b)\n",
    "res1.backward()\n",
    "print(a.grad)\n",
    "res2.backward()\n",
    "print(a.grad)\n",
    "# Градиенты от разных backward'ов суммируются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyNetwork(nn.Module):\n",
    "layer = nn.Linear(5, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 120])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ReLU()\n",
    "nn.Softmax()\n",
    "nn.Sigmoid()\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1832, 0.1981, 0.2220, 0.2677, 0.3721],\n",
       "        [0.0189, 0.8390, 0.0228, 0.8926, 0.1471],\n",
       "        [0.9135, 0.9029, 0.8834, 0.0852, 0.4602]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_network = nn.Sequential(\n",
    "    nn.Linear(5, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 120),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 240])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_network(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net2 = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + self.net2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu(x) = max(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net2 = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + self.net2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1', Linear(in_features=5, out_features=120, bias=True)),\n",
       "             ('relu1', ReLU()),\n",
       "             ('linear2', Linear(in_features=120, out_features=120, bias=True)),\n",
       "             ('relu2', ReLU())])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrderedDict([\n",
    "    (\"linear1\", nn.Linear(5, 120)),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"linear2\", nn.Linear(120, 120)),\n",
    "    (\"relu2\", nn.ReLU())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "network = nn.Sequential(\n",
    "    OrderedDict([\n",
    "    (\"linear1\", nn.Linear(5, 120)),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"linear2\", nn.Linear(120, 120)),\n",
    "    (\"relu2\", nn.ReLU())])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2138, -0.2845, -0.2805,  0.1737,  0.2926, -0.1410, -0.2665, -0.0678,\n",
       "         0.2077, -0.3188,  0.3166,  0.2051, -0.2892, -0.1978,  0.3302,  0.1572,\n",
       "         0.3567,  0.1865,  0.0644, -0.1787,  0.3360,  0.1241, -0.1205,  0.0390,\n",
       "         0.2918,  0.1208, -0.4313,  0.0209,  0.1856,  0.1950, -0.1485, -0.3020,\n",
       "        -0.4166, -0.2791, -0.1374,  0.0092, -0.2525,  0.0530, -0.4292, -0.1949,\n",
       "         0.3344, -0.3895, -0.2450, -0.0671, -0.2787,  0.3165, -0.1548, -0.0353,\n",
       "        -0.0849,  0.3587,  0.0144, -0.2429,  0.3243,  0.0778,  0.1311,  0.3958,\n",
       "         0.3736, -0.2255, -0.0383, -0.3281,  0.4166, -0.2308,  0.2349,  0.0384,\n",
       "        -0.3481,  0.1185,  0.1877, -0.3284, -0.4185, -0.1121,  0.1396,  0.4469,\n",
       "        -0.1359,  0.1708, -0.2195,  0.2097, -0.4250, -0.2390, -0.2251, -0.0630,\n",
       "         0.1865,  0.1422, -0.2716,  0.2364,  0.0958,  0.4108, -0.2648,  0.1096,\n",
       "        -0.4250,  0.2710, -0.4389,  0.0334,  0.1373, -0.0071, -0.0019,  0.1401,\n",
       "        -0.2606,  0.2500, -0.2585, -0.1780, -0.2189,  0.3070,  0.0214, -0.1073,\n",
       "        -0.2117,  0.3448,  0.3408, -0.1559,  0.0351,  0.1845,  0.4390, -0.0645,\n",
       "        -0.2155, -0.4077,  0.2046, -0.0088, -0.3413,  0.1964,  0.0270,  0.2170],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.linear1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружать веса можно с диска\n",
    "# network.state_dict()\n",
    "# state_dict = torch.load(fname)\n",
    "# network.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset\n",
    "# абстрактный класс в котором есть методы __getitem__ и __len__\n",
    "lis = [1,2,3]\n",
    "lis[0] == lis.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lis) == lis.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def preprocess(self, x):\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"x\": self.preprocess(self.x[idx]), \"y\": self.y[idx]}\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(torch.rand(120, 5), torch.randint(0, 2, (120,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0.7863, 0.8376, 0.8148, 0.2392, 0.3573]), 'y': tensor(1)}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0.7863, 0.8376, 0.8148, 0.2392, 0.3573],\n",
      "        [0.8323, 0.8461, 0.0236, 0.2344, 0.3110],\n",
      "        [0.7666, 0.3392, 0.7404, 0.0287, 0.8597],\n",
      "        [0.2001, 0.0875, 0.0315, 0.6662, 0.3548],\n",
      "        [0.2939, 0.3686, 0.6583, 0.2923, 0.1980],\n",
      "        [0.3671, 0.5126, 0.8011, 0.2153, 0.0055],\n",
      "        [0.1561, 0.1134, 0.5276, 0.4412, 0.9078],\n",
      "        [0.0589, 0.5901, 0.0262, 0.0769, 0.5226],\n",
      "        [0.4491, 0.0928, 0.4785, 0.0999, 0.2028],\n",
      "        [0.7370, 0.3892, 0.0782, 0.3187, 0.3517],\n",
      "        [0.4809, 0.5383, 0.2021, 0.3802, 0.6442],\n",
      "        [0.3413, 0.4733, 0.6799, 0.3744, 0.4116]]), 'y': tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0])}\n",
      "{'x': tensor([[0.1597, 0.4480, 0.2654, 0.7138, 0.7055],\n",
      "        [0.6687, 0.8004, 0.3314, 0.4152, 0.4291],\n",
      "        [0.1271, 0.2182, 0.9989, 0.3848, 0.6651],\n",
      "        [0.5474, 0.2973, 0.6526, 0.4703, 0.5582],\n",
      "        [0.6746, 0.5628, 0.1429, 0.7084, 0.7119],\n",
      "        [0.7276, 0.6448, 0.1078, 0.1436, 0.2769],\n",
      "        [0.4623, 0.6334, 0.3228, 0.2209, 0.1491],\n",
      "        [0.6117, 0.3763, 0.8388, 0.3413, 0.8795],\n",
      "        [0.0490, 0.2980, 0.1204, 0.7458, 0.9470],\n",
      "        [0.5100, 0.0095, 0.2389, 0.9155, 0.2306],\n",
      "        [0.8859, 0.1966, 0.9980, 0.5247, 0.2495],\n",
      "        [0.9631, 0.0256, 0.1754, 0.2311, 0.0263]]), 'y': tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0])}\n",
      "{'x': tensor([[0.3690, 0.7472, 0.8951, 0.4349, 0.2167],\n",
      "        [0.4669, 0.2761, 0.3354, 0.7243, 0.8117],\n",
      "        [0.1667, 0.1816, 0.5552, 0.0872, 0.6084],\n",
      "        [0.2626, 0.6021, 0.7396, 0.4394, 0.5019],\n",
      "        [0.1254, 0.5047, 0.9125, 0.2822, 0.8890],\n",
      "        [0.6520, 0.1602, 0.0019, 0.8474, 0.3408],\n",
      "        [0.9505, 0.0811, 0.0923, 0.9605, 0.0266],\n",
      "        [0.9658, 0.1716, 0.8370, 0.5379, 0.4844],\n",
      "        [0.1343, 0.5530, 0.0089, 0.7843, 0.6563],\n",
      "        [0.3285, 0.0787, 0.5433, 0.7931, 0.2203],\n",
      "        [0.1352, 0.0403, 0.3141, 0.5470, 0.3358],\n",
      "        [0.2272, 0.5930, 0.3463, 0.7081, 0.9487]]), 'y': tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0])}\n",
      "{'x': tensor([[0.5438, 0.8451, 0.5736, 0.6860, 0.9911],\n",
      "        [0.8693, 0.8389, 0.7904, 0.3404, 0.6395],\n",
      "        [0.5983, 0.2201, 0.1182, 0.5918, 0.3230],\n",
      "        [0.3336, 0.4870, 0.8770, 0.9590, 0.8505],\n",
      "        [0.9276, 0.1433, 0.1038, 0.4788, 0.4436],\n",
      "        [0.7697, 0.1339, 0.9751, 0.5055, 0.2420],\n",
      "        [0.5428, 0.7086, 0.3229, 0.0609, 0.8157],\n",
      "        [0.6622, 0.5130, 0.6049, 0.3564, 0.6397],\n",
      "        [0.5609, 0.0496, 0.5374, 0.0322, 0.3455],\n",
      "        [0.2879, 0.8476, 0.3933, 0.7058, 0.4306],\n",
      "        [0.3755, 0.9538, 0.4805, 0.9671, 0.6104],\n",
      "        [0.4808, 0.1865, 0.4298, 0.3147, 0.1913]]), 'y': tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])}\n",
      "{'x': tensor([[0.2290, 0.7861, 0.8255, 0.9017, 0.0839],\n",
      "        [0.3185, 0.0254, 0.0711, 0.4176, 0.9622],\n",
      "        [0.8922, 0.7263, 0.2723, 0.4932, 0.0431],\n",
      "        [0.2383, 0.9228, 0.4682, 0.4774, 0.1304],\n",
      "        [0.8298, 0.5232, 0.1471, 0.8231, 0.8425],\n",
      "        [0.4813, 0.7961, 0.3151, 0.6830, 0.7474],\n",
      "        [0.3725, 0.0853, 0.1573, 0.0447, 0.3863],\n",
      "        [0.3349, 0.7627, 0.8733, 0.4379, 0.3267],\n",
      "        [0.5740, 0.8143, 0.6678, 0.9427, 0.9853],\n",
      "        [0.5050, 0.7015, 0.8783, 0.1489, 0.8557],\n",
      "        [0.1938, 0.3329, 0.3227, 0.2989, 0.0893],\n",
      "        [0.4792, 0.6656, 0.3265, 0.0234, 0.8048]]), 'y': tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])}\n",
      "{'x': tensor([[0.9001, 0.1045, 0.4183, 0.6311, 0.1904],\n",
      "        [0.6730, 0.4723, 0.3034, 0.8191, 0.5631],\n",
      "        [0.9197, 0.1074, 0.3769, 0.7004, 0.2268],\n",
      "        [0.3796, 0.3201, 0.0229, 0.3370, 0.7503],\n",
      "        [0.7490, 0.7864, 0.6021, 0.1167, 0.5230],\n",
      "        [0.0717, 0.0170, 0.9529, 0.8076, 0.7472],\n",
      "        [0.8301, 0.2734, 0.6493, 0.7344, 0.4742],\n",
      "        [0.2763, 0.6135, 0.0179, 0.7757, 0.3905],\n",
      "        [0.6739, 0.0976, 0.5964, 0.2903, 0.5822],\n",
      "        [0.5443, 0.8741, 0.2930, 0.0459, 0.7521],\n",
      "        [0.9500, 0.5461, 0.1444, 0.8826, 0.7764],\n",
      "        [0.9470, 0.7478, 0.4195, 0.6384, 0.3928]]), 'y': tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0])}\n",
      "{'x': tensor([[0.0451, 0.2561, 0.2763, 0.7232, 0.6871],\n",
      "        [0.7527, 0.4665, 0.3876, 0.4370, 0.7295],\n",
      "        [0.2764, 0.9092, 0.4358, 0.3439, 0.4642],\n",
      "        [0.6211, 0.8031, 0.7004, 0.4683, 0.6036],\n",
      "        [0.7416, 0.8898, 0.9014, 0.0843, 0.9992],\n",
      "        [0.4652, 0.9430, 0.8975, 0.5992, 0.2791],\n",
      "        [0.9260, 0.7567, 0.4796, 0.2541, 0.2898],\n",
      "        [0.5290, 0.6507, 0.9001, 0.9996, 0.6941],\n",
      "        [0.7098, 0.8698, 0.1331, 0.7221, 0.2024],\n",
      "        [0.8116, 0.2855, 0.2387, 0.5285, 0.5389],\n",
      "        [0.0860, 0.2313, 0.8195, 0.7501, 0.1832],\n",
      "        [0.2348, 0.8482, 0.7620, 0.8317, 0.4951]]), 'y': tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0])}\n",
      "{'x': tensor([[0.7313, 0.9663, 0.9953, 0.5003, 0.0861],\n",
      "        [0.4057, 0.1741, 0.5271, 0.6112, 0.1972],\n",
      "        [0.4860, 0.8073, 0.7776, 0.6919, 0.2238],\n",
      "        [0.0692, 0.6226, 0.9019, 0.8029, 0.4123],\n",
      "        [0.2314, 0.2307, 0.3218, 0.5800, 0.7970],\n",
      "        [0.2449, 0.6519, 0.3807, 0.8534, 0.7931],\n",
      "        [0.2778, 0.3292, 0.9738, 0.0903, 0.6971],\n",
      "        [0.6138, 0.4621, 0.0603, 0.3498, 0.1751],\n",
      "        [0.1117, 0.6288, 0.8334, 0.3392, 0.4373],\n",
      "        [0.5278, 0.9780, 0.7034, 0.8081, 0.4274],\n",
      "        [0.4033, 0.7191, 0.6506, 0.6774, 0.7070],\n",
      "        [0.7636, 0.0817, 0.5905, 0.7351, 0.2493]]), 'y': tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])}\n",
      "{'x': tensor([[0.9038, 0.0479, 0.7301, 0.5373, 0.0651],\n",
      "        [0.6546, 0.2861, 0.5333, 0.2269, 0.9466],\n",
      "        [0.2729, 0.3495, 0.2419, 0.0788, 0.9053],\n",
      "        [0.3815, 0.1612, 0.8719, 0.0754, 0.9214],\n",
      "        [0.0190, 0.8324, 0.6253, 0.1142, 0.5842],\n",
      "        [0.9326, 0.8693, 0.1980, 0.8688, 0.4577],\n",
      "        [0.8372, 0.3043, 0.6219, 0.7212, 0.5725],\n",
      "        [0.5637, 0.0495, 0.9918, 0.6613, 0.7260],\n",
      "        [0.8947, 0.4303, 0.1231, 0.4915, 0.9471],\n",
      "        [0.3798, 0.4506, 0.6830, 0.0423, 0.0210],\n",
      "        [0.9054, 0.2206, 0.5298, 0.4625, 0.3609],\n",
      "        [0.8057, 0.5771, 0.8047, 0.5040, 0.4902]]), 'y': tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1])}\n",
      "{'x': tensor([[0.3727, 0.3655, 0.7968, 0.3121, 0.5458],\n",
      "        [0.5107, 0.2206, 0.2018, 0.2226, 0.1136],\n",
      "        [0.7465, 0.2336, 0.3883, 0.9997, 0.1006],\n",
      "        [0.9384, 0.9262, 0.1625, 0.0174, 0.3805],\n",
      "        [0.2340, 0.2970, 0.1280, 0.5997, 0.9798],\n",
      "        [0.2360, 0.2524, 0.9858, 0.6804, 0.2377],\n",
      "        [0.8223, 0.4553, 0.0323, 0.8239, 0.1149],\n",
      "        [0.9415, 0.5674, 0.4251, 0.0137, 0.0625],\n",
      "        [0.8598, 0.5315, 0.8748, 0.8980, 0.5263],\n",
      "        [0.8955, 0.7571, 0.6511, 0.6580, 0.8279],\n",
      "        [0.9654, 0.9712, 0.6180, 0.6318, 0.7488],\n",
      "        [0.7251, 0.6567, 0.0823, 0.4809, 0.0366]]), 'y': tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "for item in dl:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "dataset_train = MNIST(\"./mnist\", download=True, train=True, \n",
    "                      transform=torchvision.transforms.ToTensor())\n",
    "dataset_test = MNIST(\"./mnist\", download=True, train=False,\n",
    "                     transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.324509382247925\n",
      "1.833387851715088\n",
      "0.8033930659294128\n",
      "0.5727453231811523\n",
      "0.37661415338516235\n",
      "0.4378845989704132\n",
      "0.37872111797332764\n",
      "0.4406692683696747\n",
      "0.43145155906677246\n",
      "0.4559275507926941\n",
      "0.3372312132269144 tensor(0.9091)\n",
      "0.24504129588603973\n",
      "0.27750569581985474\n",
      "0.20284505188465118\n",
      "0.2775854766368866\n",
      "0.20138587057590485\n",
      "0.2797655761241913\n",
      "0.2510136365890503\n",
      "0.3204866945743561\n",
      "0.27840346097946167\n",
      "0.3170830011367798\n",
      "0.23825159225947198 tensor(0.9391)\n",
      "0.153513103723526\n",
      "0.19755102694034576\n",
      "0.13508474826812744\n",
      "0.20898553729057312\n",
      "0.15430328249931335\n",
      "0.20291830599308014\n",
      "0.1978721171617508\n",
      "0.25713273882865906\n",
      "0.22168269753456116\n",
      "0.23605255782604218\n",
      "0.1873925607651472 tensor(0.9545)\n",
      "0.1166420429944992\n",
      "0.16152657568454742\n",
      "0.10666035115718842\n",
      "0.17788277566432953\n",
      "0.12416583299636841\n",
      "0.16503289341926575\n",
      "0.1631646603345871\n",
      "0.21460697054862976\n",
      "0.1939205676317215\n",
      "0.1822759062051773\n",
      "0.15531528492768606 tensor(0.9642)\n",
      "0.09732671082019806\n",
      "0.1393555849790573\n",
      "0.09031619876623154\n",
      "0.159383162856102\n",
      "0.10237377136945724\n",
      "0.13357284665107727\n",
      "0.14149276912212372\n",
      "0.18963325023651123\n",
      "0.1753634661436081\n",
      "0.1474078893661499\n",
      "0.1351584457935622 tensor(0.9701)\n",
      "0.08566883206367493\n",
      "0.11891892552375793\n",
      "0.0788016989827156\n",
      "0.1431579440832138\n",
      "0.08935921639204025\n",
      "0.10672261565923691\n",
      "0.12745656073093414\n",
      "0.16403456032276154\n",
      "0.16421255469322205\n",
      "0.12222856283187866\n",
      "0.12127586590567938 tensor(0.9748)\n",
      "0.07587794214487076\n",
      "0.10525507479906082\n",
      "0.06574839353561401\n",
      "0.1284385323524475\n",
      "0.07980643957853317\n",
      "0.08513420075178146\n",
      "0.1155955046415329\n",
      "0.1376260370016098\n",
      "0.15219879150390625\n",
      "0.10471498221158981\n",
      "0.11041795186853658 tensor(0.9784)\n",
      "0.06619181483983994\n",
      "0.09234490990638733\n",
      "0.05383666604757309\n",
      "0.11480703949928284\n",
      "0.07195895910263062\n",
      "0.07174742966890335\n",
      "0.10522639751434326\n",
      "0.11688515543937683\n",
      "0.14030595123767853\n",
      "0.09048476815223694\n",
      "0.1038566344560912 tensor(0.9809)\n",
      "0.057773567736148834\n",
      "0.07904490828514099\n",
      "0.045613642781972885\n",
      "0.10234084725379944\n",
      "0.06493239104747772\n",
      "0.06330331414937973\n",
      "0.09702557325363159\n",
      "0.09928934276103973\n",
      "0.1313256025314331\n",
      "0.07857772707939148\n",
      "0.09810569891795659 tensor(0.9830)\n",
      "0.05008908361196518\n",
      "0.06824271380901337\n",
      "0.038233544677495956\n",
      "0.09043758362531662\n",
      "0.05847935378551483\n",
      "0.054717857390642166\n",
      "0.08870051801204681\n",
      "0.08613870292901993\n",
      "0.12266111373901367\n",
      "0.06861227750778198\n",
      "0.09403353976085782 tensor(0.9835)\n"
     ]
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(dataset_train, batch_size=128)\n",
    "test_dl = DataLoader(dataset_test, batch_size=128)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    for idx, (images, labels) in enumerate(train_dl):\n",
    "        preds = network(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 50 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "\n",
    "    cumulative_loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(test_dl): \n",
    "            preds = network(images)\n",
    "            loss = criterion(preds, labels)\n",
    "            cumulative_loss += loss.item()\n",
    "            acc += (preds.argmax(1) == labels).float().mean()\n",
    "    print(cumulative_loss / idx, acc / idx)\n",
    "    #if idx % 50 == 0:\n",
    "    #    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним веса нейросети\n",
    "torch.save(network.state_dict(), \"./network_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
